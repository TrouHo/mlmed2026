% Report.3.tex  
\documentclass[conference]{IEEEtran}

\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{hyperref}

\title{COVID-19 Infection Segmentation from Chest X-ray Images using a Lightweight U-Net}

\author{
\IEEEauthorblockN{Ho Huyen Chau}
\IEEEauthorblockA{
Machine Learning in Medicine 2026\\
University of Science and Technology of Hanoi (USTH)\\
Email: chauhh.23bi14067@usth.edu.vn
}
}

\begin{document}
\maketitle

\begin{abstract}
This report presents a practical study on segmenting COVID-19 infection regions in chest X-ray (CXR) images using the COVID-QU-Ex dataset. I implement a lightweight U-Net model for binary infection segmentation and evaluate performance using the Dice coefficient. Due to computational constraints, I train on a reduced subset of the dataset while demonstrating a complete pipeline. 

\end{abstract}

\begin{IEEEkeywords}
COVID-19, chest X-ray, medical image segmentation, U-Net, Dice coefficient
\end{IEEEkeywords}

% -------------------------
\section{Introduction}
Chest X-ray imaging is widely used for diagnosing lung diseases due to its low cost and availability. For COVID-19, localizing infected regions can provide pixel-level information beyond image-level classification. In this report, I study infection segmentation on chest X-ray images using the COVID-QU-Ex dataset and implement a lightweight U-Net model to predict binary infection masks. The goal is to demonstrate an end-to-end segmentation workflow under limited computational resources, rather than achieving state-of-the-art performance.

% -------------------------
\section{Dataset Description}
\subsection{Dataset Overview}
The COVID-QU-Ex dataset contains chest X-ray (CXR) images grouped into three categories: COVID-19, Non-COVID infections (e.g., viral or bacterial pneumonia), and Normal cases. In addition to the images, the dataset provides ground-truth segmentation masks for lung regions and infection regions, enabling supervised segmentation experiments.

\subsection{Folder Structure}
The dataset is organized into predefined splits \texttt{Train}, \texttt{Val}, and \texttt{Test}. For each class, the following folders are provided:
\begin{itemize}
  \item \texttt{images/}: chest X-ray images
  \item \texttt{infection masks/}: infection segmentation masks
  \item \texttt{lung masks/}: lung segmentation masks
\end{itemize}

\subsection{Dataset Imbalance}
Table~\ref{tab:class_dist} reports the number of training images per class based on my dataset inspection. COVID-19 has a larger number of samples compared to Non-COVID and Normal cases, indicating a class imbalance.

\begin{table}[ht]
\centering
\caption{Training set class distribution (COVID-QU-Ex).}
\label{tab:class_dist}
\begin{tabular}{l r}
\toprule
\textbf{Class} & \textbf{\# Images (Train)} \\
\midrule
COVID-19 & 1864 \\
Non-COVID & 932 \\
Normal & 932 \\
\bottomrule
\end{tabular}
\end{table}


\subsection{Empty Infection Masks and Motivation for COVID-19 Only}
When scanning infection masks in the training set, I found that 1864 out of 3728 masks are empty (all-zero). This strongly suggests that many samples (especially Normal and often Non-COVID) contain no annotated infection regions. Table~\ref{tab:empty_masks} summarizes this observation.

\begin{table}[ht]
\centering
\caption{Empty infection masks in the training split.}
\label{tab:empty_masks}
\begin{tabular}{l r}
\toprule
\textbf{Property} & \textbf{Value} \\
\midrule
Total infection masks (Train) & 3728 \\
Empty infection masks (Train) & 1864 \\
Empty mask ratio & 0.50 \\
\bottomrule
\end{tabular}
\end{table}

Therefore, I decided not to train on Normal and Non-COVID samples as empty infection masks can bias the model toward predicting background-only masks (trivial solution). It means to ensure meaningful learning of infection patterns, I restrict training and validation to COVID-19 samples for the infection segmentation task.

% -------------------------
\section{Methodology}
\subsection{Preprocessing}
All images are loaded as grayscale and resized to a fixed resolution to reduce computation. In my main experiment, I set the input size to $256 \times 256$. Pixel intensities are normalized to $[0,1]$. Infection masks are resized using nearest-neighbor interpolation and binarized to ensure consistent labels. During training, I apply light augmentation (random horizontal flip and small random rotations) to improve robustness.

\subsection{Model Architecture}
I use a lightweight U-Net architecture for binary segmentation. U-Net follows an encoder--decoder design with skip connections to combine spatial details from early layers with semantic features in deeper layers. The model outputs a single-channel logit map which is converted to probabilities using a sigmoid function.

\subsection{Loss Function and Optimization}
Infection regions occupy a relatively small portion of the image, creating strong foreground--background imbalance. To address this, I use a combined loss:
\begin{equation}
\mathcal{L} = \mathcal{L}_{\text{BCE}} + \mathcal{L}_{\text{Dice}}.
\end{equation}
I train the model with the Adam optimizer (learning rate $10^{-3}$). The best checkpoint is selected based on validation Dice score.

% -------------------------
\section{Experiments and Results}
\subsection{Evaluation Metric}
I evaluate segmentation performance using the Dice coefficient, which measures overlap between prediction $P$ and ground truth $G$:
\begin{equation}
\text{Dice}(P,G) = \frac{2|P \cap G|}{|P| + |G|}.
\end{equation}
Dice is commonly used in medical segmentation because it is sensitive to class imbalance.

\subsection{Main Result}
Using only COVID-19 samples with a subset of 600 training images and 100 validation images at $256 \times 256$ resolution, the best validation Dice score achieved is:
\begin{center}
\textbf{Best validation Dice = 0.7005}.
\end{center}

\subsection{Hyperparameter Comparison}
To demonstrate the effect of different settings, Table~\ref{tab:hyperparam} compares two configurations that I tested. Because the objective is to present the workflow under limited resources, I report results obtained from small subsets rather than full-dataset training.

\begin{table}[ht]
\centering
\caption{Results with different training settings (COVID-19 only).}
\label{tab:hyperparam}
\begin{tabular}{c c c c}
\toprule
\textbf{IMG\_SIZE} & \textbf{\#Train} & \textbf{\#Val} & \textbf{Best Val Dice} \\
\midrule
128 & 300 & 50 & 0.6787 \\
256 & 600 & 100 & 0.7005 \\
\bottomrule
\end{tabular}
\end{table}

% -------------------------
\section{Discussion and Limitations}
Although the model achieves a reasonable Dice score under constrained settings, several limitations remain. First, experiments are conducted on reduced subsets of the dataset, which may limit generalization. Second, resizing images to low or medium resolution (e.g., $128\times128$ or $256\times256$) may reduce boundary precision for small infection regions. Finally, no advanced architectures or post-processing methods are applied. Future improvements could include training on larger subsets, using higher resolution, incorporating lung masks as a region-of-interest constraint, or adopting stronger segmentation backbones.

% -------------------------
\section{Conclusion}
This report demonstrates an end-to-end pipeline for COVID-19 infection segmentation on chest X-ray images using the COVID-QU-Ex dataset. I implement a lightweight U-Net model with a BCE+Dice loss and evaluate performance using the Dice coefficient. Despite limited resources and subset training, the model achieves a best validation Dice score of 0.7005 and produces meaningful qualitative predictions.

%  References
\begin{thebibliography}{1}

\bibitem{ronneberger2015unet}
O. Ronneberger, P. Fischer, and T. Brox, ``U-Net: Convolutional Networks for Biomedical Image Segmentation,'' in \emph{MICCAI}, 2015.

\end{thebibliography}

\end{document}
